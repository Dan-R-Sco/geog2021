{
 "metadata": {
  "name": "",
  "signature": "sha256:5c6fc325f764822460c7970775f6fb9e28f95bd82acee220aef7bfb9781c94fa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img style=\"float: left\" src=\"images/ucl_logo.png\">\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Spatial filtering using ENVI 5.2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Prof. P. Lewis & Dr. M. Disney\n",
      "\n",
      "Remote Sensing Unit\n",
      "\n",
      "Dept. Geography\n",
      "\n",
      "UCL"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Aims"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " After completing this practical, you should be able to answer the questions: Which type of filter should I use for a given filtering application? What impact will the size and shape of the filter have on the output? You should have some understanding of the process (and issues) of spatial filtering of EO data using Envi. \n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Contents"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[top](#Image-Display-and-Enhancement-using-ENVI-5.2)]\n",
      "[[Introduction](#1.-Introduction)]\n",
      "[[Exploration](#2.-Exploration)]\n",
      "[[Spectral Features](#3.-Spectral-Features)]\n",
      "[[Spectral Profiles](#4.-Spectral-Profiles)]\n",
      "[[Enhancement](#5.-Enhancement)]\n",
      "[[Comparing Images](#6.-Comparing-Images)]\n",
      "[[More Exploring](#7.-More-Exploring)]\n",
      "[[Summary](#8.-Summary)]"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The datasets you need for this practical are available from:\n",
      "\n",
      "\n",
      "* [ETM-190600](https://github.com/profLewis/geog2021/blob/master/practical1/ETM-190600)\n",
      "* [ETM-190600.HDR](https://github.com/profLewis/geog2021/blob/master/practical1/ETM-190600.HDR)\n",
      "* [TM-280589](https://github.com/profLewis/geog2021/blob/master/practical1/TM-280589)\n",
      "* [TM-280589.HDR](https://github.com/profLewis/geog2021/blob/master/practical1/TM-280589.HDR)\n",
      "\n",
      "\n",
      "You should download these data and put them in a directory (folder) that you will remember!\n",
      "\n",
      "The data you will be using are:\n",
      "\n",
      "* six wavebands of a Landsat TM image over Greater London, imaged on May 28th 1989. The data were obtained from the GLCF which maintains a large database of (freely available) Landsat and other imagery. The data are at an original pixel spacing of 28.5 m, but have been resampled to a 25 m grid here. The data are in a Transverse Mercator projection with OSGB 1936 datum. \n",
      "\n",
      "* six wavebands (nominally the same wavelengths) of a Landsat ETM image with 25 m spatial resolution, covering the same spatial extent. These data were obtained on June 19th 2000. The data were obtained from Landmap which contains a database available to Universities and other users through an Athens login (done via the institution you are at). \n",
      "\n",
      "The wavebands are:\n",
      "\n",
      "|1|2|3|4|5|6|\n",
      "| --- | --- | --- | --- | --- | --- |\n",
      "|450-520 nm|520-600 nm| 630-690 nm|760-900 nm|1550-1750 nm|2080-2350 nm|\n",
      "\n",
      "The extent of the imagery is (Lat/Lon): \n",
      "\n",
      "$$\n",
      "    51^o 43'   9.23'' North, 0^o 36' 18.37'' West \n",
      "$$\n",
      "\n",
      "to\n",
      "\n",
      "\n",
      "$$\n",
      "    51^o 16' 29.32'' North,  0^o 27' 24.60'' East\n",
      "$$\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      " 1. Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***In this section, we load the image data we wish to explore***."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The purpose of this practical is for you to build on practical 1 and learn about the process of spatial (convolution) filtering. \n",
      "\n",
      "Note that convolution is a mathematical operation involving the modification of one function by another to produce a third (output) function. In spatial fitering this implies the operation of a filter (one function) on an input image (another function) to produce a filtered image (the output).\n",
      "\n",
      "The session will be normally run as one two hour supervised practical. You may not complete all tasks in detail in that time, so once you get the hang of how to use the tools, move on to the next section and return later to think more about the remote sensing. \n",
      "\n",
      "There is a good material for this in text books (e.g. Jensen, Curran etc.) and some of this is online e.g. much of the Jensen material. Relevant material is made available for you [here](jensen). There are also [some of Jensen's notes](jensen/Chapter 8.1_2011.pdf), covering spatial filtering (but also with some good material on histogram manipulation that is worth reading).\n",
      "\n",
      "There is also an additional practical exercise [here](jensen/jensen/EX08/Exercise.ipynb).\n",
      "\n",
      "First, obtain and then load the `TM` and `ETM` images of London that we used in a previous practical. \n",
      "\n",
      "**View the ETM image as a FCC.**\n",
      "\n",
      "![](images/fcc1.png)\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. Convolution filtering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***In this section, we use various tools for image convolution***.\n",
      "\n",
      "A description of the various options for convolution and morphology are as [envi help pages](http://www.exelisvis.com/docs/ConvolutionMorphologyFilters.html). You should have a quick read over this if you are not familiar with the types of filter we will be using.\n",
      "\n",
      "These operations are available via the `Toolbox` menu:\n",
      "\n",
      "![](images/toolbox2.png)\n",
      "\n",
      "\n",
      "***Make sure you make notes of what you have done and how you have done it so you can recall this later.***"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3. Spectral Features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***In this section, we will learn how to consider spectral features and perform contrast enhancement***.\n",
      "\n",
      "Clearly, we can 'recognise' much information in the image from spatial context.\n",
      "\n",
      "![](images/rgb.jpg)\n",
      "\n",
      "But there are other ways we can visualise the data to aid our interpretation. \n",
      "\n",
      "For example, if we select the `Custom stretch` button: ![custom](images/custom.png)\n",
      "\n",
      "then we obtain a histogram view of the data, within which we can apply a contrast stretch by 'moving' the upper and lower thresholds.\n",
      "\n",
      "\n",
      "For greyscale:\n",
      "\n",
      "![hist](images/hist.png)\n",
      "\n",
      "or three band colour:\n",
      "\n",
      "![hist](images/hist1.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This can be useful both for performing a contrast stretch\n",
      "\n",
      "***experiment with this so that you understand what the linear contrast enhancement is doing to the image DN*** You may find it useful to save some historgrams and images and put these in your notes.\n",
      "\n",
      "It is also of value in visualising the features of the histogram. The histogram shows the frequency of occurrence of the different DNs in the image. For example in the image above, we can describe the blue waveband histogram (shown in blue) as having two clear peaks and a long positive tail. The two peaks are most likely indicative of different land cover classes. The fact that there is a long positive tail may show a third 'bright' class present.\n",
      "\n",
      "***explore the histograms shown by some of the wavebands you have access to here***\n",
      "\n",
      "As you do this, think about the relationship between the informations shown in the image and that in the histogram. \n",
      "\n",
      "* How could you try to use the histogram to perform a classification on the image into different land cover classes?\n",
      "* What issues might you come across?\n",
      "* Do some bands show better separatbility than others? if so, which (and why?)\n",
      "* A histogram is a useful way of summarising the information in an image. In fact, we will often use even simpler descriptors to decsribe a frequency distribution such as this, one example being the *mean* and *standard deviation*. Would it be a good idea to describe these histograms in this way? If not, why not?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One way of extending our view of such summary data is to use a scatter plot (often called a 'feature space' plot).\n",
      "\n",
      "***locate the scatter plot button, and display a scatter plot with the red waveband on the x axis and the NIR on the y axis***\n",
      "\n",
      "![](images/scatter.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You should see that you are able to define ('draw') regions onto the scatter plot, and the pixels within this specified region are then displayed in the defined colour on the image:\n",
      "\n",
      "![](images/scatter1.png)\n",
      "\n",
      "![](images/scatter1a.jpg)\n",
      "\n",
      "***You should spend some time exploring this for different wavebands, as this concept forms the basis of many remote sensing algorithms (particularly those for classification)***\n",
      "\n",
      "As you do this, think about how the scatter plot and histogram information are related and also think about how you might get the computer to *describe* the regions you have drawn in the feature space plot.\n",
      "\n",
      "Think also about how using only one or two wavebands may be a limiting factor in classification (i.e. there is often information in other bands that may allow separability)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4. Spectral Profiles"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***In this section, we will learn how to do plot spectral profiles***.\n",
      "\n",
      "Although we can display (up to) three bands of information in a colour composite, we often wish to know more information.\n",
      "\n",
      "The various `Display->Profiles` tools can help in this regard as we can look at the DN in all wavebands (for a particular pixel).\n",
      "\n",
      "The following show some example spectral profiles:\n",
      "\n",
      "![Profile 1](images/spec1.png)\n",
      "\n",
      "![Profile 2](images/spec2.png)\n",
      "\n",
      "![Profile 3](images/spec3.png)\n",
      "\n",
      "**See if you can navigate your way to these locations and/or work out what 'material' is shown by the spectral profile**."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "5. Enhancement"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***In this section, we will learn how to perform a variety of enhancement tasks***.\n",
      "\n",
      "We have seen that ENVI has simple image display enhancement capabilities such as 'brightness' and 'contrast' variation via contrtol sliders.\n",
      "\n",
      "These are often useful first pass enhancement tools to enable you to more readily visualise features in the image.\n",
      "\n",
      "Several 'automated' or semi-automated approaches also exist that may provide a useful enhancement under certain conditions. \n",
      "\n",
      "These are available via a menu as:\n",
      "\n",
      "![](images/histlist.png)\n",
      "\n",
      "For example,histogram equalisation is generally a useful visual enhancement method:\n",
      "\n",
      "![](images/nohist.png)\n",
      "![](images/histo1.png)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "![](images/histapp.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***Explore the impact of various enhancement operations***\n",
      "\n",
      "You may find it easiest to do this using a 'greyscale' representation (so there is just a single waveband to think about).\n",
      "\n",
      "Think about how the different enhancements relate to the information in the histogram.\n",
      "\n",
      "***In particular, explore how you can use image enhancement to more readily differentiate different DN levels in a particular area of the image (e.g. the river)***"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another form of enhancement is to make use of *colour* to differentiate different DNs. We call such an enhancement 'pseudocolour' (note that this is very different to false colour or real colour: make sure you understand the distinction).\n",
      "\n",
      "To examine this idea, load a greyscale image of the ETM dataset.\n",
      "\n",
      "Then change the colour table, for exaple to 'rainbow':\n",
      "\n",
      "![](images/pseudo.png)\n",
      "\n",
      "![](images/colour.png)\n",
      "\n",
      "\n",
      "You should be able to use the histogram `custom stretch` facility to expand or compress the colour range or use different 'colours' to examine particular features in more detail (e.g. paths in parks, or features in the river).\n",
      "\n",
      "![](images/colour1.png)\n",
      "\n",
      "That said, analysis using greyscale is often easier to interpret, with appropriate enhancement:\n",
      "\n",
      "\n",
      "![](images/grey.png)\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "6. Comparing Images"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***In this section, we will examine some tools to use when comparing images***.\n",
      "\n",
      "Often, we wish to compare features from more than one image (e.g. Landsat images taken over an interval of time).\n",
      "\n",
      "There are several tools for exploring this in ENVI.\n",
      "\n",
      "First, remove the current loaded images from ENVI (Note down how you do this!), then load two dataset `ETM-190600` and `TM-280589` as fasle colour composites.\n",
      "\n",
      "One immediately obvious thing you can do is simply toggle each dataset `'on` and '`off` once it is loaded (using the dataset check box).\n",
      "\n",
      "You can use tools we have seen above, such as the scatterplot to visualise the scatter between the two datasets:\n",
      "\n",
      "![](images/two.png)\n",
      "\n",
      "You can also very usefully 'draw' on this scatterplot to identify interesting features:\n",
      "\n",
      "![](images/pink.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Transparency"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another option is to use the transparency slider ![](images/trans.png) to give different 'weights' of the two datasets. This might be useful, for instance to spot features that have changed between the two image dates:\n",
      "\n",
      "![](images/z1.png)\n",
      "\n",
      "![](images/z2.png)\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Swipe and Flicker"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sometimes it is useful to 'flicker' between the various images or swipe one over the other to spot features of (change) interest.\n",
      "\n",
      "These can be done using the appropriate buttons on the command bar:\n",
      "\n",
      "![](images/flk.png)\n",
      "\n",
      "![](images/swipe.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Views"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One other option is to change the number of 'views' on the screen display:\n",
      "\n",
      "![](images/views.png)\n",
      "\n",
      "This will create new 'views':\n",
      "\n",
      "![](images/view2.png)\n",
      "\n",
      "And you can drag and drop loaded datasets to the particular view you want.\n",
      "\n",
      "***Use these various comparison tools to highlight areas of difference between the two images***"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "7. More Exploring"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some other interesting options to explore:\n",
      "\n",
      "### Annotation\n",
      "\n",
      "On the control bar, you should see options for annotating the image. Experiment with annotating the image for a few features and work out how to save a 'picture' of what you have done (e.g. `File -> Chip view to-> File ...`):\n",
      "\n",
      "![chip](images/chip.jpg)\n",
      "\n",
      "### Google Earth\n",
      "\n",
      "If you have tools such as [Google Earth](http://www.google.co.uk/intl/en_uk/earth/) set up on the computer you are using, try `File->Chip view to->Google Earth`\n",
      "\n",
      "![googlr earth](images/google.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "8. Summary"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The main aim of this practical is to get you used to using the image processing software tool `envi`.\n",
      "\n",
      "In this practical, we have loaded two Landsat images of London and used various tools within `envi` to visualise the data and their information content.\n",
      "\n",
      "In particular, we have learned about:\n",
      "\n",
      "* Image Display\n",
      "    * False Colour Composites\n",
      "    * Real Colour Composites\n",
      "    * Greyscale display\n",
      "    * Pseudocolour\n",
      "    * Spectral profiles\n",
      "\n",
      "\n",
      "* Feature Space\n",
      "    * Histograms\n",
      "    * Scatterplots\n",
      "    \n",
      "    \n",
      "* Enhancement\n",
      "    * Linear contrast enhancement\n",
      "    * Histogram equalisation\n",
      "    \n",
      "[[top](#Image-Display-and-Enhancement-using-ENVI-5.2)]\n",
      "[[Introduction](#1.-Introduction)]\n",
      "[[Exploration](#2.-Exploration)]\n",
      "[[Spectral Features](#3.-Spectral-Features)]\n",
      "[[Spectral Profiles](#4.-Spectral-Profiles)]\n",
      "[[Enhancement](#5.-Enhancement)]\n",
      "[[Comparing Images](#6.-Comparing-Images)]\n",
      "[[More Exploring](#7.-More-Exploring)]\n",
      "[[Summary](#8.-Summary)]"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}